{"cells":[{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"XcfNYpZIhfB1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"clx4CVvpESYh"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Convolution1D, AveragePooling1D\n","from tensorflow.keras.layers import concatenate\n","from sklearn.svm import SVR\n","import scipy.stats as stats\n","\n","from tensorflow.keras.layers import Input, GRU, Bidirectional\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Convolution1D, MaxPooling1D\n","from tensorflow.keras.layers import Multiply"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Euu8bHBY9Svh"},"outputs":[],"source":["from google.colab import drive\n","drive_dir = '/content/drive'\n","drive.mount(drive_dir, force_remount=True)"]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"PwYM6Wrzhr1E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DvGBKL4bI-oZ"},"outputs":[],"source":["# needs to be uploaded from you device\n","CNNSVR_train_data = pd.read_csv(\"/content/cnn-svr_training_example.csv\")\n","# print(CNNSVR_train_data.head())\n","CNN_SVR_test_data = pd.read_csv(\"/content/cnn-svr_testing_example.csv\")\n","# print(CNN_SVR_test_data.head())\n","CNN_SVR_weight_path = \"/content/cnn-svr_weights.h5\"\n","\n","CRNN_test_data = pd.read_csv(\"/content/input_example.csv\")\n","# print(CRNN_test_data.head())\n","CRNN_weight_path = \"/content/C_RNNCrispr_weights.h5\""]},{"cell_type":"markdown","metadata":{"id":"ALmhZbM6qGj6"},"source":["# CNN-SVR model building\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTxa8grP-sVb"},"outputs":[],"source":["# Model\n","def grna_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    seq = np.zeros((data_n, length, 4), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        seq_temp = data\n","        for i in range(length):\n","            if seq_temp[i] in \"Aa\":\n","                seq[l, i, 0] = 1\n","            elif seq_temp[i] in \"Cc\":\n","                seq[l, i, 1] = 1\n","            elif seq_temp[i] in \"Gg\":\n","                seq[l, i, 2] = 1\n","            elif seq_temp[i] in \"Tt\":\n","                seq[l, i, 3] = 1\n","    return seq\n","\n","\n","def epi_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    epi = np.zeros((data_n, length), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        epi_temp = data\n","        for i in range(length):\n","            if epi_temp[i] in \"A\":\n","                epi[l, i] = 1\n","            elif epi_temp[i] in \"N\":\n","                epi[l, i] = 0\n","    return epi\n","\n","\n","def preprocess(file_path, usecols):\n","    data = pd.read_csv(file_path, usecols=usecols)\n","    data = np.array(data)\n","    ctcf, dnase, h3k4me3, rrbs = epi_preprocess(data[:, 0]), epi_preprocess(data[:, 1]), epi_preprocess(data[:, 2]), epi_preprocess(data[:, 3])\n","    epi = []\n","    for i in range(len(data)):\n","        ctcf_t, dnase_t, h3k4me3_t, rrbs_t = pd.DataFrame(ctcf[i]), pd.DataFrame(dnase[i]), pd.DataFrame(h3k4me3[i]), pd.DataFrame(rrbs[i])\n","        epi_t = pd.concat([ctcf_t, dnase_t, h3k4me3_t, rrbs_t], axis=1)\n","        epi_t = np.array(epi_t)\n","        epi.append(epi_t)\n","    epi = np.array(epi)\n","    return epi\n","\n","\n","def load_data(train_file, test_file):\n","    train_data = pd.read_csv(train_file, usecols=[4, 9])\n","    train_data = np.array(train_data)\n","    train_seq, train_y = train_data[:, 0], train_data[:, 1]\n","    train_seq = grna_preprocess(train_seq)\n","    train_epi = preprocess(train_file, [5, 6, 7, 8])\n","    train_y = train_y.reshape(len(train_y), -1)\n","\n","    test_data = pd.read_csv(test_file, usecols=[4, 9])\n","    test_data = np.array(test_data)\n","    test_seq, test_y = test_data[:, 0], test_data[:, 1]\n","    test_seq = grna_preprocess(test_seq)\n","    test_epi = preprocess(test_file, [5, 6, 7, 8])\n","    test_y = test_y.reshape(len(test_y), -1)\n","    return train_seq, test_seq, train_epi, test_epi, train_y, test_y\n","\n","\n","def build_model():\n","    tensor_input = Input(shape=(23, 8))\n","    seq_input, epi_input = tf.split(tensor_input, 2, axis=2)\n","\n","    dropout = 0.3\n","    seq_conv1 = Convolution1D(256, 5, kernel_initializer='glorot_uniform', name='seq_conv_1')(seq_input)\n","    seq_act1 = Activation('relu', name='seq_activation1')(seq_conv1)\n","    seq_pool1 = AveragePooling1D(2, name='seq_pooling_1')(seq_act1)\n","    seq_drop1 = Dropout(dropout)(seq_pool1)\n","\n","    seq_conv2 = Convolution1D(256, 5, kernel_initializer='glorot_uniform', name='seq_conv_2')(seq_drop1)\n","    seq_act2 = Activation('relu', name='seq_activation_2')(seq_conv2)\n","    seq_pool2 = AveragePooling1D(2, name='seq_pooling_2')(seq_act2)\n","    seq_drop2 = Dropout(dropout)(seq_pool2)\n","    seq_flat = Flatten()(seq_drop2)\n","\n","    seq_dense1 = Dense(256, activation='relu', name='seq_dense_1')(seq_flat)\n","    seq_drop3 = Dropout(dropout)(seq_dense1)\n","    seq_dense2 = Dense(128, activation='relu', name='seq_dense_2')(seq_drop3)\n","    seq_drop4 = Dropout(dropout)(seq_dense2)\n","    seq_dense3 = Dense(64, activation='relu', name='seq_dense_3')(seq_drop4)\n","    seq_drop5 = Dropout(dropout)(seq_dense3)\n","    seq_out = Dense(40, activation='relu', name='seq_dense_4')(seq_drop5)\n","\n","    epi_conv1 = Convolution1D(256, 5, kernel_initializer='glorot_uniform', name='epi_conv_1')(epi_input)\n","    epi_act1 = Activation('relu', name='epi_activation_1')(epi_conv1)\n","    epi_pool1 = AveragePooling1D(2, name='epi_pooling_1')(epi_act1)\n","    epi_drop1 = Dropout(dropout)(epi_pool1)\n","\n","    epi_conv2 = Convolution1D(256, 5, kernel_initializer='glorot_uniform', name='epi_conv_2')(epi_drop1)\n","    epi_act2 = Activation('relu', name='epi_activation_2')(epi_conv2)\n","    epi_pool2 = AveragePooling1D(2, name='epi_pooling_2')(epi_act2)\n","    epi_drop2 = Dropout(dropout)(epi_pool2)\n","    epi_flat = Flatten()(epi_drop2)\n","\n","    epi_dense1 = Dense(256, activation='relu', name='epi_dense_1')(epi_flat)\n","    epi_drop3 = Dropout(dropout)(epi_dense1)\n","    epi_dense2 = Dense(128, activation='relu', name='epi_dense_2')(epi_drop3)\n","    epi_drop4 = Dropout(dropout)(epi_dense2)\n","    epi_dense3 = Dense(64, activation='relu', name='epi_dense_3')(epi_drop4)\n","    epi_drop5 = Dropout(dropout)(epi_dense3)\n","    epi_out = Dense(40, activation='relu', name='epi_dense_4')(epi_drop5)\n","\n","    merged = concatenate([seq_out, epi_out], axis=-1)\n","\n","    model = Model(inputs=tensor_input, outputs=[merged])\n","\n","    # # Load weights for the model\n","    # print(\"Loading weights for the models\")\n","    # model.load_weights(weight_path, by_name=True)\n","\n","    # prediction = Dense(1, activation='linear', name='prediction')(merged)\n","    # final_model = Model([seq_input, epi_input], prediction)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"GbuD17TlPRAt"},"source":["Try out CNN-SVR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR5mAbiKKcP3"},"outputs":[],"source":["# Load weights for the model\n","print(\"Loading weights for the models\")\n","model = build_model()\n","model.load_weights(weight_path, by_name = True)\n","\n","# Load training and testing data\n","print(\"Loading training and testing data\")\n","seq_train, seq_test, epi_train, epi_test, y_train, y_test = load_data(train_data_path, test_data_path)\n","input_train = tf.concat([seq_train, epi_train], 2)\n","input_test = tf.concat([seq_test, epi_test], 2)\n","\n","# Training and testing data shape\n","print(\"training sequence data shape: \" + str(seq_train.shape))\n","print(\"training epigenetic data shape: \" + str(epi_train.shape))\n","print(\"training combined data shape: \" + str(input_train.shape))\n","\n","print(\"testing sequence data shape: \" + str(seq_test.shape))\n","print(\"testing epigenetic data shape: \" + str(epi_test.shape))\n","print(\"testing combined data shape: \" + str(input_test.shape))\n","\n","\n","# Predict on data\n","print(\"Predicting on training and testing data\")\n","x_train = model.predict(input_train)\n","x_test = model.predict(input_test)\n","\n","print(\"output (training) shape: \" + str(x_train.shape))\n","print(\"output (testing) shape: \" + str(x_test.shape))\n","\n","x_train, x_test = np.array(x_train), np.array(x_test)\n","\n","# Select important features from outputs of the CNN model\n","selected_cnn_fea_cols = [17, 26, 9, 19, 30, 6, 12, 39, 36, 21, 22, 3, 25]\n","x_train = x_train[:, selected_cnn_fea_cols]\n","x_test = x_test[:, selected_cnn_fea_cols]\n","\n","print(\"training data shape: \" + str(x_train.shape))\n","print(\"testing data shape: \" + str(x_test.shape))\n","\n","y_train = np.array(y_train).ravel()\n","y_test = np.array(y_test).ravel()\n","\n","# SVR model\n","clf = SVR(kernel=\"rbf\", gamma=0.12, C=1.7, epsilon=0.11, verbose=1)\n","# Fit the SVR model according to the given training data\n","clf.fit(x_train, y_train)\n","\n","# Perform regression on samples in x_train\n","y_pred_train = clf.predict(x_train)\n","# Perform regression on samples in x_test\n","y_pred = clf.predict(x_test)\n","\n","# Output from SVR\n","print(\"prediction: \" + str(y_pred))\n","print(\"target: \" + str(y_test))"]},{"cell_type":"markdown","source":["# CRNNCrispr model building\n"],"metadata":{"id":"6uFrWG8skJNg"}},{"cell_type":"code","source":["# Model\n","def grna_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    seq = np.zeros((data_n, length, 4), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        seq_temp = data\n","        for i in range(length):\n","            if seq_temp[i] in \"Aa\":\n","                seq[l, i, 0] = 1\n","            elif seq_temp[i] in \"Cc\":\n","                seq[l, i, 1] = 1\n","            elif seq_temp[i] in \"Gg\":\n","                seq[l, i, 2] = 1\n","            elif seq_temp[i] in \"Tt\":\n","                seq[l, i, 3] = 1\n","    return seq\n","\n","\n","def epi_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    epi = np.zeros((data_n, length), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        epi_temp = data\n","        for i in range(length):\n","            if epi_temp[i] in \"A\":\n","                epi[l, i] = 1\n","            elif epi_temp[i] in \"N\":\n","                epi[l, i] = 0\n","    return epi\n","\n","\n","def preprocess(file_path, usecols):\n","    data = pd.read_csv(file_path, usecols=usecols)\n","    data = np.array(data)\n","    epi_1, epi_2, epi_3, epi_4 = epi_preprocess(data[:, 0]), epi_preprocess(data[:, 1]), epi_preprocess(data[:, 2]), epi_preprocess(data[:, 3])\n","    epi = []\n","    for i in range(len(data)):\n","        epi_1_temp, epi_2_temp, epi_3_temp, epi_4_temp = pd.DataFrame(epi_1[i]), pd.DataFrame(epi_2[i]), pd.DataFrame(\n","            epi_3[i]), pd.DataFrame(epi_4[i])\n","        epi_temp = pd.concat([epi_1_temp, epi_2_temp, epi_3_temp, epi_4_temp], axis=1)\n","        epi_temp = np.array(epi_temp)\n","        epi.append(epi_temp)\n","    epi = np.array(epi)\n","    return epi\n","\n","\n","def load_data(test_file):\n","    test_data = pd.read_csv(test_file, usecols=[4, 9])\n","    test_data = np.array(test_data)\n","    x_test, y_test = test_data[:, 0], test_data[:, 1]\n","    x_test = grna_preprocess(x_test)\n","    epi_test = preprocess(test_file, [5, 6, 7, 8])\n","    y_test = y_test.reshape(len(y_test), -1)\n","    return x_test, epi_test, y_test\n","\n","def build_CRNNCrispr():\n","    tensor_input = Input(shape=(23, 8))\n","    seq_input, epi_input = tf.split(tensor_input, 2, axis=2)\n","\n","    seq_conv1 = Convolution1D(256, 5, kernel_initializer='random_uniform', name='seq_conv1')(seq_input)\n","    seq_act1 = Activation('relu')(seq_conv1)\n","    seq_pool1 = MaxPooling1D(2)(seq_act1)\n","    seq_drop1 = Dropout(0.2)(seq_pool1)\n","    gru1 = Bidirectional(GRU(256, kernel_initializer='he_normal', dropout=0.3, recurrent_dropout=0.2, reset_after=False), name='gru1')(seq_drop1)\n","    seq_dense1 = Dense(256, name='seq_dense1')(gru1)\n","    seq_act2 = Activation('relu')(seq_dense1)\n","    seq_drop2 = Dropout(0.3)(seq_act2)\n","    seq_dense2 = Dense(128, name='seq_dense2')(seq_drop2)\n","    seq_act3 = Activation('relu')(seq_dense2)\n","    seq_drop3 = Dropout(0.2)(seq_act3)\n","    seq_dense3 = Dense(64, name='seq_dense3')(seq_drop3)\n","    seq_act4 = Activation('relu')(seq_dense3)\n","    seq_drop4 = Dropout(0.2)(seq_act4)\n","    seq_dense4 = Dense(40, name='seq_dense4')(seq_drop4)\n","    seq_act5 = Activation('relu')(seq_dense4)\n","    seq_drop5 = Dropout(0.2)(seq_act5)\n","\n","    epi_conv1 = Convolution1D(256, 5, name='epi_conv1')(epi_input)\n","    epi_act1 = Activation('relu')(epi_conv1)\n","    epi_pool1 = MaxPooling1D(2)(epi_act1)\n","    epi_drop1 = Dropout(0.3)(epi_pool1)\n","    epi_dense1 = Dense(256, name='epi_dense1')(epi_drop1)\n","    epi_act2 = Activation('relu')(epi_dense1)\n","    epi_drop2 = Dropout(0.2)(epi_act2)\n","    epi_dense2 = Dense(128, name='epi_dense2')(epi_drop2)\n","    epi_act3 = Activation('relu')(epi_dense2)\n","    epi_drop3 = Dropout(0.3)(epi_act3)\n","    epi_dense3 = Dense(64, name='epi_dense3')(epi_drop3)\n","    epi_act4 = Activation('relu')(epi_dense3)\n","    epi_drop4 = Dropout(0.3)(epi_act4)\n","    epi_act5 = Dense(40, name='epi_dense4')(epi_drop4)\n","    epi_out = Activation('relu')(epi_act5)\n","\n","    seq_epi_m = Multiply()([seq_drop5, epi_out])\n","    seq_epi_drop = Dropout(0.2)(seq_epi_m)\n","    seq_epi_flat = Flatten()(seq_epi_drop)\n","    seq_epi_output = Dense(1, activation='linear')(seq_epi_flat)\n","\n","    return Model(inputs=tensor_input, outputs=[seq_epi_output])"],"metadata":{"id":"QjWJJRT7kMkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load and try out CRNNCrispr\n","print(\"Loading weights for the models\")\n","CRNNCrispr_model = build_CRNNCrispr()\n","CRNNCrispr_model.load_weights(weight_path) # needs to upload\n","\n","print(\"Loading test data\")\n","x_test, epi_test, y_test = load_data(data_path) # needs to upload\n","\n","print(\"input sequence data shape: \" + str(x_test.shape))\n","print(\"input epigenetic data shape: \" + str(epi_test.shape))\n","input_test = tf.concat([x_test, epi_test], 2)\n","\n","print(\"Predicting on test data\")\n","y_pred = CRNNCrispr_model.predict(input_test, batch_size=256, verbose=2)\n","print(\"output prediction shape: \" + str(y_pred.shape))\n","print(\"output target shape: \" + str(y_test.shape))\n","\n","# result = pd.concat([y_test, y_pred], axis=1)\n","# result.to_csv(result_file, index=False, sep=',', header=['y_test', 'y_pred'])"],"metadata":{"id":"Pn53S1hTkb0z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yo4CC5Y7KtWT"},"source":["# Saliency Map"]},{"cell_type":"code","source":["def count_nonzero(saliency_map):\n","    count = 0\n","    nonzero = []\n","    for i in range(len(saliency_map)):\n","        if np.any(saliency_map[i]):\n","            count += 1\n","            nonzero.append(i)\n","    return count, nonzero\n","\n","\n","def count_nonzero_grad(saliency_map):\n","    count = 0\n","    for i in saliency_map:\n","        if np.any(i):\n","            count += 1\n","    return count\n","\n","\n","def find_max(saliency_map):\n","    max = 0\n","    index = 0\n","    for i in range(len(saliency_map)):\n","        cur = np.sum(np.abs(np.array(saliency_map[i]).ravel()))\n","        if cur > max:\n","            max = cur\n","            index = i\n","    return max, index"],"metadata":{"id":"HV1wBTULk-rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvCYbqNEqLQK"},"outputs":[],"source":["def generate_saliency_map(input, model, target_layer_idx=-1):\n","    # Finds the target layer\n","    target_layer = Model(inputs=model.input, outputs=model.layers[target_layer_idx].output)\n","    tensor_input = tf.cast(input, tf.float32)\n","\n","    with tf.GradientTape(persistent = True) as tape:\n","        tape.watch(tensor_input)\n","        output = target_layer(tensor_input)\n","\n","    # grads = [tape.gradient(output[:, i], [seq, epi]) for i in range(output.shape[1])]\n","    jacob = tape.batch_jacobian(output, tensor_input)\n","\n","    # Normalize the gradients\n","    print(\"Dimension original: \" + str(jacob.shape))\n","    jacob /= (tf.reduce_max(tf.abs(jacob), axis = (2,3), keepdims = True) + 1e-8)\n","    print(\"Dimension after: \" + str(jacob.shape))\n","\n","    # Clean up the persistent gradient tape\n","    del tape\n","\n","    return jacob\n","\n","\n","CNNSVR_saliency_map = generate_saliency_map(input_train[:100], model)\n","\n","CNNSVR_model_output = model(input_train[:100])\n","\n","print(\"Model outputs shape: \" + str(CNNSVR_model_output.shape))\n","print(\"Input data saliency map shape: \" + str(CNNSVR_saliency_map.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kymUwz8bA9EC"},"outputs":[],"source":["print(str(count_nonzero(CNNSVR_model_output)[0]) + \" out of \" + str(len(model_output))\n","+ \" samples in the CNNSVR model outputs are nonzero\")\n","print(str(count_nonzero(CNNSVR_saliency_map)[0]) + \" out of \" + str(len(saliency_map))\n","+ \" samples in the CNNSVR saliency maps are nonzero\")\n","print(str(count_nonzero(CNNSVR_saliency_map)[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVtCtEFNPXgk"},"outputs":[],"source":["_, max_index = find_max(CNNSVR_saliency_map)\n","print(max_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTUSvWdUJxry"},"outputs":[],"source":["num_map, map_list = count_nonzero(CNNSVR_saliency_map[max_index])\n","\n","print(num_map)\n","print(map_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPbIhK7-Ei0w"},"outputs":[],"source":["def draw_saliency_map(saliency_map,):\n","    # Normalize the saliency map\n","    saliency_map /= (tf.reduce_max(tf.abs(saliency_map)) + 1e-8)\n","\n","    # Transpose the map to match the format in the paper\n","    saliency_map = np.transpose(saliency_map)\n","\n","    # Create a heatmap by applying a colormap (e.g., 'viridis')\n","    heatmap = plt.get_cmap('viridis')(saliency_map)\n","\n","    # Display the original image, saliency map, and overlaid image\n","    plt.figure(figsize=(12, 6))\n","    plt.imshow(saliency_map, cmap='viridis')\n","    plt.colorbar()\n","\n","    plt.title('Saliency Map of CNN-SVR for max data that is nonzero')\n","    y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","    y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","    x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","    x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","    plt.xticks(x_ticks, x_tick_labels)\n","    plt.yticks(y_ticks, y_tick_labels)\n","\n","    plt.xlabel('Genomic Position')\n","    plt.ylabel('Nucleotide')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvuT71JcEmS4"},"outputs":[],"source":["for i in map_list:\n","  draw_saliency_map(CNNSVR_saliency_map[max_index][i])"]},{"cell_type":"code","source":["# Saliency Map for CRNNCrispr\n","def generate_saliency_map(input, model, target_layer_idx=-1):\n","    # Finds the target layer\n","    target_layer = Model(inputs=model.input, outputs=model.layers[target_layer_idx].output)\n","\n","    # Compute the gradients of the target class with respect to the model's output\n","    tensor_input = tf.convert_to_tensor(input, dtype=tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(tensor_input)\n","        output = target_layer(tensor_input)\n","    grads = tape.gradient(output, tensor_input)\n","\n","    # Normalize the gradients\n","    grads /= (tf.reduce_max(tf.abs(grads), axis=(1,2), keepdims=True) + 1e-8)\n","\n","    # Create a saliency map by averaging the absolute gradients across color channels\n","    # saliency_map = np.mean(np.abs(grads[0]), axis=-1)\n","    saliency_map = grads\n","\n","    return saliency_map\n","\n","data_path = \"/content/x_input_reg.npy\"\n","# seq, epi, label = load_data(data_path)\n","# concat_input = tf.concat([seq, epi], 2)\n","# concat_input = tf.cast(concat_input, tf.float32)\n","concat_input = np.transpose(np.squeeze(np.load(data_path)), [0,2,1])\n","print(concat_input.shape)\n","CRNN_saliency_map = generate_saliency_map(concat_input, CRNNCrispr_model)\n","CRNN_prediction = CRNNCrispr_model(concat_input)\n","print(CRNN_saliency_map.shape)\n","print(CRNN_prediction.shape)"],"metadata":{"id":"0fahOuURlWOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(str(count_nonzero_grad(CRNN_saliency_map)) + \" out of \" + str(len(CRNN_saliency_map))\n","+ \" samples in the saliency map of the sequencial inputs are nonzero\")"],"metadata":{"id":"MFrlPhOwlin_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_saliency_map(saliency_map[index], 'Saliency Map of CRNNCrispr for max frequency')"],"metadata":{"id":"dgLVyE5Cl8pi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DeepCRISPR Saliency maps\n"],"metadata":{"id":"UR4_hnBjTuRW"}},{"cell_type":"code","source":["saliency_map_cls = np.load('saliency_values_class.npy')\n","saliency_map_cls.shape # (100, 1, 23, 8)\n","\n","#100: saliency map for 100 different data points.\n","#1: single chanel\n","#23: length of sequencedat\n","#8: number of features A, C, G, T , CTCF, Dnase, H3k4me3, RRBS\n","\n","saliency_map_cls = saliency_map_cls[:, :, :, :]  # Assuming single channel saliency map\n","print(saliency_map_cls.shape)\n","\n","x_cls = np.load('x_input_class.npy')\n","x_cls = x_cls[:, :, :, :]  # Assuming single channel saliency map\n","print(x_cls.shape)"],"metadata":{"id":"-Ud6LuuoTJY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_index = 0\n","\n","x_cls_sqz = np.squeeze(x_cls[sample_index])\n","print(x_cls_sqz.shape)\n","saliency_map_cls_sqz = np.squeeze(saliency_map_cls[sample_index])\n","saliency_map_cls_sqz = saliency_map_cls_sqz.transpose()\n","\n","\n","# Plot the original input and its saliency map\n","\n","plt.imshow(x_cls_sqz, cmap='gray')\n","plt.title('Original Input for DeepCRISPR Classification')\n","plt.show()\n","\n","plt.imshow(saliency_map_cls_sqz)\n","plt.title('Saliency Map for DeepCRISPR Classification')\n","plt.show()"],"metadata":{"id":"DUB-447KTM5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_sqz = np.squeeze(saliency_map_cls, axis=1)  # Resulting shape: (100, 23, 8)\n","print(cls_sqz.shape)\n","cls_sum = np.sum(cls_sqz, axis=0).transpose() # Resulting shape: (23, 8)\n","print(cls_sum.shape)\n","heatmap = plt.get_cmap('viridis')(cls_sum)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(cls_sum, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR Classification')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()"],"metadata":{"id":"phF4Ri9ETPSs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### On-target Sequential Regression Task\n"],"metadata":{"id":"dUu0ZDGMhMdc"}},{"cell_type":"code","source":["saliency_map_seq = np.load('saliency_values_seq.npy')\n","print(saliency_map_seq.shape)\n","#10: saliency map for 100 different data points.\n","#1: single chanel\n","#23: length of sequencedat\n","#4: number of features A, C, G, T , CTCF, Dnase, H3k4me3, RRBS\n","\n","x_seq = np.load('x_input_seq.npy')\n","x_seq = x_seq[:, :, :, :]  # Assuming single channel saliency map\n","print(x_seq.shape)"],"metadata":{"id":"x9ce0oWzfoXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_index = 0\n","\n","x_seq_sqz = np.squeeze(x_seq[sample_index])\n","print(x_seq_sqz.shape)\n","saliency_map_seq_sqz = np.squeeze(saliency_map_seq[sample_index])\n","print(saliency_map_seq_sqz.shape)\n","saliency_map_seq_sqz = saliency_map_seq_sqz.transpose()\n","\n","\n","# Plot the original input and its saliency map\n","\n","plt.imshow(x_seq_sqz, cmap='gray')  # Assuming grayscale input\n","plt.title('Original Input for DeepCRISPR Sequential Regression ')\n","plt.show()\n","\n","plt.imshow(saliency_map_seq_sqz)  # Assuming grayscale input\n","plt.title('Saliency Map for DeepCRISPR Sequential Regression')\n","plt.show()"],"metadata":{"id":"hu4K643AhjnA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_sqz = np.squeeze(saliency_map_seq, axis=1)  # Resulting shape: (100, 23, 8)\n","seq_sum = np.sum(seq_sqz, axis=0).transpose() # Resulting shape: (23, 8)\n","\n","heatmap = plt.get_cmap('viridis')(seq_sum)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(seq_sum, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR Sequential Regression Task')\n","y_ticks = np.arange(0, 4, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()"],"metadata":{"id":"orltdqyMhkuO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### On-target epigenetic regression task"],"metadata":{"id":"FF1j-PlFjFJx"}},{"cell_type":"code","source":["saliency_map_reg = np.load('saliency_values_reg_norm.npy')\n","saliency_map_reg.shape # (100, 1, 23 ,8)\n","#100: saliency map for 100 different data points.\n","#1: single chanel\n","#23: length of sequencedat\n","#8: number of features A, C, G, T , CTCF, Dnase, H3k4me3, RRBS\n","\n","saliency_map_reg = saliency_map_reg[:, :, :, :]  # Assuming single channel saliency map\n","print(saliency_map_reg.shape)\n","\n","x_reg = np.load('x_input_reg.npy')\n","x_reg = x_reg[:, :, :, :]  # Assuming single channel saliency map\n","print(x_reg.shape)"],"metadata":{"id":"LEePsm3mi5pf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_index = 0\n","\n","x_reg_sqz = np.squeeze(x_reg[sample_index])\n","print(x_reg_sqz.shape)\n","saliency_map_reg_sqz = np.squeeze(saliency_map_reg[sample_index])\n","saliency_map_reg_sqz = saliency_map_reg_sqz.transpose()\n","\n","\n","# Plot the original input and its saliency map\n","\n","plt.imshow(x_reg_sqz, cmap='gray')\n","plt.title('Original Input for DeepCRISPR Regression Task')\n","plt.show()\n","\n","plt.imshow(saliency_map_reg_sqz)\n","plt.title('Saliency Map for DeepCRISPR Regression Task')\n","plt.show()"],"metadata":{"id":"voHtieBnjIy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_input = np.load('y_input.npy')\n","predicted_on_target = np.load('predicted_on_target.npy')"],"metadata":{"id":"3sn0V2MCpccB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_value = np.mean(y_input)\n","mean_index = np.where(np.isclose(y_input, mean_value, atol=1e-3))[0]\n","\n","print(\"mean value:\", mean_value)\n","print(\"meen seq :\", x_reg[mean_index])\n","print(\"mean index:\", mean_index)\n","\n","saliency_map_reg_mean_sqz = np.squeeze(saliency_map_reg[mean_index])\n","saliency_map_reg_mean_sqz = saliency_map_reg_mean_sqz.transpose()\n","\n","heatmap = plt.get_cmap('viridis')(saliency_map_reg_mean_sqz)\n","\n","plt.figure(figsize=(12, 6))\n","plt.imshow(saliency_map_reg_mean_sqz, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR of mean')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()"],"metadata":{"id":"-HhRC1MWjJve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_index = np.argmin(y_input) # 16\n","print(\"min value:\", y_input[min_index])\n","print(\"min seq :\", x_reg[min_index])\n","print(\"min index:\", min_index)\n","saliency_map_reg_min_sqz = np.squeeze(saliency_map_reg[min_index]) #17 #85\n","saliency_map_reg_min_sqz = saliency_map_reg_min_sqz.transpose()\n","\n","heatmap = plt.get_cmap('viridis')(saliency_map_reg_min_sqz)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(saliency_map_reg_min_sqz, cmap='viridis')\n","plt.colorbar()\n","\n","# plt.title('Saliency Map for Regression Task for max frequency')\n","plt.title('Saliency Map for DeepCRISPR for min frequency')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()"],"metadata":{"id":"u-QuMZsVuJjL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_index = np.argmax(y_input) # 16\n","print(\"max value:\", y_input[max_index])\n","print(\"max seq :\", x_reg[max_index])\n","print(\"max index:\", max_index)\n","\n","\n","saliency_map_reg_max_sqz = np.squeeze(saliency_map_reg[max_index])\n","saliency_map_reg_max_sqz = saliency_map_reg_max_sqz.transpose()\n","\n","heatmap = plt.get_cmap('viridis')(saliency_map_reg_max_sqz)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(saliency_map_reg_max_sqz, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for for DeepCRISPR of max frequency')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()"],"metadata":{"id":"y4ughfMFuJrs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","padded_seq = np.pad(seq_2, ((0, 0), (0, 0), (0, 0), (0, num_zeros_to_pad)), mode='constant')\n","data = np.concatenate((padded_seq, saliency_map_reg[:-2]))\n","\n","# data = saliency_map_reg[:-2]\n","num_datasets = data.shape[0]\n","print(num_datasets)\n","data_squeezed = np.squeeze(data, axis=1)  # Resulting shape: (100, 23, 8)\n","summed_data = np.sum(data_squeezed, axis=0)  # Resulting shape: (23, 8)\n","\n","ft_importance = summed_data / num_datasets\n","ft_importance = ft_importance.transpose()\n","\n","\n","heatmap = plt.get_cmap('viridis')(ft_importance)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(ft_importance, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR Regression')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()\n"],"metadata":{"id":"13CfagIx4UOD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### On-target Reg Feature Importance Map"],"metadata":{"id":"AKPwBqU_nV3h"}},{"cell_type":"code","source":["# Maybe sum up all data within diff category?\n","\n","cls_1 = saliency_map_cls\n","seq_2 = saliency_map_seq\n","reg_3 = saliency_map_reg\n","\n","num_zeros_to_pad = 8 - seq_2.shape[-1]\n","print(num_zeros_to_pad)\n","\n","padded_seq = np.pad(seq_2, ((0, 0), (0, 0), (0, 0), (0, num_zeros_to_pad)), mode='constant')\n","cls_reg = np.concatenate((cls_1, reg_3))\n","\n","# Concatenate concatenated_array1 and array3 along the last axis\n","final_result = np.concatenate((cls_reg, padded_seq))\n","final_result.shape\n"],"metadata":{"id":"wpy2uOZWUEMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data = np.concatenate((saliency_map_cls, saliency_map_reg))\n","# print(data.shape)\n","# num_datasets = data.shape[0]\n","# print(num_datasets)\n","\n","data = final_result\n","num_datasets = data.shape[0]\n","print(num_datasets)\n","data_squeezed = np.squeeze(data, axis=1)  # Resulting shape: (100, 23, 8)\n","summed_data = np.sum(data_squeezed, axis=0)  # Resulting shape: (23, 8)\n","\n","ft_importance = summed_data / num_datasets\n","ft_importance = ft_importance.transpose()\n","\n","\n","heatmap = plt.get_cmap('viridis')(ft_importance)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(ft_importance, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR for all tasks')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()\n"],"metadata":{"id":"2Fy3ZVozUEMq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Other 2 models comparison visualizatiton"],"metadata":{"id":"g4er5N3gnwOu"}},{"cell_type":"code","source":["import pandas as pd\n","\n","def grna_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    seq = np.zeros((data_n, length, 4), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        seq_temp = data\n","        for i in range(length):\n","            if seq_temp[i] in \"Aa\":\n","                seq[l, i, 0] = 1\n","            elif seq_temp[i] in \"Cc\":\n","                seq[l, i, 1] = 1\n","            elif seq_temp[i] in \"Gg\":\n","                seq[l, i, 2] = 1\n","            elif seq_temp[i] in \"Tt\":\n","                seq[l, i, 3] = 1\n","    return seq\n","\n","\n","def epi_preprocess(lines):\n","    length = 23\n","    data_n = len(lines)\n","    epi = np.zeros((data_n, length), dtype=int)\n","    for l in range(data_n):\n","        data = lines[l]\n","        epi_temp = data\n","        for i in range(length):\n","            if epi_temp[i] in \"A\":\n","                epi[l, i] = 1\n","            elif epi_temp[i] in \"N\":\n","                epi[l, i] = 0\n","    return epi\n","\n","\n","def preprocess(file_path, usecols):\n","    data = pd.read_csv(file_path, usecols=usecols)\n","    data = np.array(data)\n","    ctcf, dnase, h3k4me3, rrbs = epi_preprocess(data[:, 0]), epi_preprocess(data[:, 1]), epi_preprocess(data[:, 2]), epi_preprocess(data[:, 3])\n","    epi = []\n","    for i in range(len(data)):\n","        ctcf_t, dnase_t, h3k4me3_t, rrbs_t = pd.DataFrame(ctcf[i]), pd.DataFrame(dnase[i]), pd.DataFrame(h3k4me3[i]), pd.DataFrame(rrbs[i])\n","        epi_t = pd.concat([ctcf_t, dnase_t, h3k4me3_t, rrbs_t], axis=1)\n","        epi_t = np.array(epi_t)\n","        epi.append(epi_t)\n","    epi = np.array(epi)\n","    return epi\n","\n","\n","def load_data(train_file):\n","    train_data = pd.read_csv(train_file, usecols=[4, 9])\n","    train_data = np.array(train_data)\n","    train_seq, train_y = train_data[:, 0], train_data[:, 1]\n","    train_seq = grna_preprocess(train_seq)\n","    train_epi = preprocess(train_file, [5, 6, 7, 8])\n","    train_y = train_y.reshape(len(train_y), -1)\n","\n","    return train_seq, train_epi, train_y\n"],"metadata":{"id":"d4ZafMJBNxaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Decode max/min sequence into binary array\n","\n","# train_seq, train_epi, train_y = load_data(\"max_min_data.csv\")\n","# seq_expand = train_seq.reshape((2, 4, 1, 23))\n","# epi_expand = train_seq.reshape((2, 4, 1, 23))\n","# merged_array = np.concatenate((seq_expand, epi_expand), axis=1)\n","# print(merged_array)\n","# print(train_y)\n","# np.save(\"merged_array.npy\", merged_array)"],"metadata":{"id":"gdcAtG0rQdsT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_cls_1 = np.squeeze(x_cls)\n","x_seq_2 = np.squeeze(x_seq)\n","x_reg_3 = np.squeeze(x_reg)\n","\n","num_zeros_to_pad = 4\n","print(num_zeros_to_pad)\n","\n","x_padded_seq = np.pad(x_seq_2, ((0, 0), (0, 4), (0, 0)), mode='constant')\n","x_cls_reg = np.concatenate((x_cls_1, x_reg_3))\n","\n","# Concatenate concatenated_array1 and array3 along the last axis\n","x_sum = np.concatenate((x_cls_reg, x_padded_seq))\n","x_sum.shape"],"metadata":{"id":"QF8Hyqvcjg72"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.save('x_sum.npy', x_sum)"],"metadata":{"id":"AzS77sAJv8LB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","data = x_reg\n","actual_frequency = y_input\n","predicted_frequency = predicted_on_target\n","\n","reshaped_data = data.reshape((100, -1))\n","\n","model = LinearRegression()\n","model.fit(reshaped_data, actual_frequency)\n","\n","feature_importance = model.coef_.reshape((8, 23))\n"],"metadata":{"id":"CPZD6-MutSqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","num_datasets, num_features, seq_length = x_sum.shape\n","\n","# Function to generate a heatmap for nucleotides or dimers importance\n","def generate_heatmap(data, title, x_labels, y_labels):\n","    plt.figure(figsize=(12, 6))\n","    plt.imshow(data, cmap='viridis', interpolation='nearest')\n","    plt.title(title)\n","    plt.xlabel(\"Genomic Position\")\n","    plt.ylabel(\"Nucleotides\")\n","    plt.xticks(np.arange(seq_length), labels=x_labels)\n","    plt.yticks(np.arange(len(y_labels)), labels=y_labels)\n","    plt.colorbar()\n","    plt.show()\n","\n","\n","\n","# Generate and display heatmaps\n","nucleotide_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']\n","\n","generate_heatmap(feature_importance, \"Feature Importance Heatmap for DeepCRISPR\", np.arange(seq_length) + 1, nucleotide_labels)\n"],"metadata":{"id":"ryilBZ4TRA3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# x_test, epi_test, y_test = load_data('C-RNNCrispr_data.csv') # needs to upload\n","# for y_indv in y_input:\n","#   if y_indv in set(y_test.flatten()):\n","#     print(y_indv)\n","# print(\"terminated\")"],"metadata":{"id":"sYG55XI6rDCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Comparison Graph"],"metadata":{"id":"N2ORyp5GcY91"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Data\n","methods = ['DeepCRISPR', 'CNN_SVR', 'CRNN']\n","spearman_values = [0.246, 0.7, 0.877]\n","auroc_values = [0.804, 0.94, 0.976]\n","\n","# Plotting\n","fig, ax = plt.subplots()\n","\n","ax.scatter(methods, spearman_values, label='Spearman', marker='o')\n","\n","ax.scatter(methods, auroc_values, label='AUROC', marker='o')\n","\n","# Adding labels and title\n","ax.set_ylabel('Performance Metrics')\n","ax.set_title('Performance Comparison of Methods')\n","ax.legend()\n","\n","plt.show()\n"],"metadata":{"id":"rdd-JF2HZPHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","#\n","methods = ['DeepCRISPR', 'CNN_SVR', 'CRNN']\n","spearman_values = [0.246, 0.7, 0.877]\n","auroc_values = [0.804, 0.94, 0.976]\n","\n","bar_width = 0.35\n","\n","index = np.arange(len(methods))\n","\n","fig, ax = plt.subplots()\n","\n","bar_spearman = ax.bar(index, spearman_values, bar_width, label='Spearman')\n","\n","bar_auroc = ax.bar(index + bar_width, auroc_values, bar_width, label='AUROC')\n","\n","ax.set_xlabel('Methods')\n","ax.set_ylabel('Performance Metrics')\n","ax.set_title('Performance Comparison of Methods')\n","ax.set_xticks(index + bar_width / 2)\n","ax.set_xticklabels(methods)\n","ax.legend()\n","\n","for bar in bar_spearman + bar_auroc:\n","    yval = bar.get_height()\n","    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n","\n","plt.show()\n"],"metadata":{"id":"D5pJKzDYusV4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6guIS2qK_1o"},"source":["# SVR Visualization"]},{"cell_type":"code","source":["# Maybe sum up all data within diff category?\n","\n","cls_1 = saliency_map_cls\n","seq_2 = saliency_map_seq\n","reg_3 = saliency_map_reg\n","\n","num_zeros_to_pad = 8 - seq_2.shape[-1]\n","print(num_zeros_to_pad)\n","\n","padded_seq = np.pad(seq_2, ((0, 0), (0, 0), (0, 0), (0, num_zeros_to_pad)), mode='constant')\n","cls_reg = np.concatenate((cls_1, reg_3))\n","\n","# Concatenate concatenated_array1 and array3 along the last axis\n","final_result = np.concatenate((cls_reg, padded_seq))\n","final_result.shape\n"],"metadata":{"id":"GkGxrUBkrNNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# data = np.concatenate((saliency_map_cls, saliency_map_reg))\n","# print(data.shape)\n","# num_datasets = data.shape[0]\n","# print(num_datasets)\n","\n","data = final_result\n","num_datasets = data.shape[0]\n","print(num_datasets)\n","data_squeezed = np.squeeze(data, axis=1)  # Resulting shape: (100, 23, 8)\n","summed_data = np.sum(data_squeezed, axis=0)  # Resulting shape: (23, 8)\n","\n","ft_importance = summed_data / num_datasets\n","ft_importance = ft_importance.transpose()\n","\n","\n","heatmap = plt.get_cmap('viridis')(ft_importance)\n","\n","# Display the original image, saliency map, and overlaid image\n","plt.figure(figsize=(12, 6))\n","plt.imshow(ft_importance, cmap='viridis')\n","plt.colorbar()\n","\n","plt.title('Saliency Map for DeepCRISPR for all tasks')\n","y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","plt.xticks(x_ticks, x_tick_labels)\n","plt.yticks(y_ticks, y_tick_labels)\n","\n","plt.xlabel('Genomic Position')\n","plt.ylabel('Nucleotide')\n","\n","plt.show()\n"],"metadata":{"id":"c_gbYXccnVCO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1wn-QpzNgT9"},"source":["PCA on the output from CNN (2D)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdTkJnO4LDEX"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","pca_2 = PCA(n_components=2)\n","\n","print(x_train.shape)\n","compressed_train = pca_2.fit_transform(x_train)\n","print(compressed_train.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BEru-TjKO1fh"},"outputs":[],"source":["x1 = compressed_train[:,0]\n","x2 = compressed_train[:,1]\n","\n","# Create a scatter plot with colors based on values\n","plt.scatter(x1, x2, c=y_train, cmap='viridis', marker='o', s=20)\n","\n","# Add a colorbar for reference\n","plt.colorbar(label='Values')\n","\n","# Set labels and title\n","plt.xlabel('Principle Component 1')\n","plt.ylabel('Principle Component 2')\n","plt.title('PCA of CNN-SVR gound truth')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gh99rlPtbZzV"},"outputs":[],"source":["x1 = compressed_train[:,0]\n","x2 = compressed_train[:,1]\n","\n","# Create a scatter plot with colors based on values\n","plt.scatter(x1, x2, c=y_pred_train, cmap='viridis', marker='o', s=20)\n","\n","# Add a colorbar for reference\n","plt.colorbar(label='Values')\n","\n","# Set labels and title\n","plt.xlabel('Principle Component 1')\n","plt.ylabel('Principle Component 2')\n","plt.title('PCA of CNN-SVR prediction')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DqWjIq_fazJ6"},"source":["PCA on the output from CNN (1D)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgekyfUua0sA"},"outputs":[],"source":["pca_1 = PCA(n_components=1)\n","\n","print(x_train.shape)\n","compressed_train_1d = pca_1.fit_transform(x_train)\n","print(compressed_train_1d.shape)\n","\n","print(x_test.shape)\n","compressed_test_1d = pca_1.fit_transform(x_test)\n","print(compressed_test_1d.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad5AvrLbUBKK"},"outputs":[],"source":["# Plot the results\n","plt.scatter(compressed_train_1d, y_train, color='darkorange', marker='o', s=20, label='data')\n","plt.plot(compressed_train_1d, y_pred_train, color='navy', lw=2, label='prediction training')\n","plt.plot(compressed_test_1d, y_pred, color='green', lw=2, label='prediction testing')\n","\n","plt.xlabel('Principle Component 1')\n","plt.ylabel('Values')\n","plt.title('SVR Visualization 1D')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["# CRNNCrispr Class Optimization"],"metadata":{"id":"8Qy5xCNmyGM2"}},{"cell_type":"code","source":["def CRNN_input_optimization_analysis(model, target_output, input_shape, num_iterations=100):\n","    np.random.seed(41)\n","    seq = tf.Variable(np.random.random(input_shape), dtype=tf.float32)\n","    np.random.seed(42)\n","    epi = tf.Variable(np.random.random(input_shape), dtype=tf.float32)\n","    optimizer = tf.optimizers.Adam(learning_rate=0.1)\n","\n","    for _ in range(num_iterations):\n","        with tf.GradientTape() as tape:\n","            output = model([tf.expand_dims(seq, axis=0), tf.expand_dims(epi, axis=0)])\n","            loss = tf.abs(output - target_output)\n","        gradients_seq, gradients_epi = tape.gradient(loss, [seq, epi])\n","        optimizer.apply_gradients(zip([gradients_seq, gradients_epi], [seq, epi]))\n","\n","    optimized_seq = seq.numpy()\n","    optimized_epi = epi.numpy()\n","    optimized_output = model.predict([np.expand_dims(optimized_seq, axis=0), np.expand_dims(optimized_epi, axis=0)])[0][0]\n","\n","    return optimized_seq, optimized_epi, optimized_output"],"metadata":{"id":"edWvM5C8KVsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimized_seq, optimized_epi, optimized_output = CRNN_input_optimization_analysis(CRNNCrispr_model, 1, (23, 4), 100)\n","print(optimized_seq.shape)\n","print(optimized_epi.shape)\n","print(optimized_output)"],"metadata":{"id":"UP6WETgL4ynU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the results\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(2, 2, 1)\n","np.random.seed(41)\n","plt.imshow(np.random.random((23, 4)))\n","plt.title('Original Random Sequencial Input')\n","plt.axis('off')\n","\n","plt.subplot(2, 2, 3)\n","np.random.seed(42)\n","plt.imshow(np.random.random((23, 4)))\n","plt.title('Original Random Epigenetic Input')\n","plt.axis('off')\n","\n","plt.subplot(2, 2, 2)\n","plt.imshow(optimized_seq)\n","plt.title('Optimized Sequencial Input')\n","plt.axis('off')\n","\n","plt.subplot(2, 2, 4)\n","plt.imshow(optimized_epi)\n","plt.title('Optimized Epigenetic Input')\n","plt.axis('off')\n","\n","plt.show()\n","\n","import numpy as np\n","\n","def decode_dna(one_hot_sequence):\n","    base_mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n","    indices = np.argmax(one_hot_sequence, axis=1)\n","    decoded_sequence = ''.join([base_mapping[idx] for idx in indices])\n","    return decoded_sequence\n","\n","print(decode_dna(optimized_seq))\n","print(decode_dna(optimized_epi))"],"metadata":{"id":"6Dm3ESiU2meZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkgWFrkDk7rY"},"source":["# SHAP VALUE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uPlirhnk-1b"},"outputs":[],"source":["!pip install deeplift\n","!pip install shap\n","from deeplift.visualization import viz_sequence\n","import shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFIgeT9Pmj2u"},"outputs":[],"source":["print(\"SHAP version is:\", shap.__version__)\n","print(\"Tensorflow version is:\", tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHNZRdKppSKT"},"outputs":[],"source":["# Data for min and max\n","deepcrispr_data_dir = \"My Drive/CSCI 2952G Final Project/x_input_reg.npy\"\n","deepcrispr_path = f\"{drive_dir}/{deepcrispr_data_dir}\"\n","\n","concat_input = np.transpose(np.squeeze(np.load(deepcrispr_path)), [0,2,1])\n","print(concat_input.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1-SecAwOqmv"},"outputs":[],"source":["# Calculate the mean of epigenetic tracks at each position\n","mean_input = tf.reduce_mean(concat_input, axis=0)\n","mean_seq, mean_epi = tf.split(mean_input, 2, axis=1)\n","print(mean_seq)\n","print(mean_epi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAfvqledo1CQ"},"outputs":[],"source":["# Defining different reference values\n","\n","# zero input\n","reference_zeroes = tf.zeros(input_test[0].shape)\n","reference_zeroes = np.ravel(reference_zeroes)\n","reference_zeroes = np.reshape(reference_zeroes, (1, reference_zeroes.shape[0]))\n","\n","print(\"reference zero input shape: \" + str(reference_zeroes.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLhblgTTQf94"},"outputs":[],"source":["# expected frequency\n","expected_fre = tf.constant([0.3, 0.2, 0.2, 0.3])\n","expected_fre = tf.reshape(expected_fre, (1, expected_fre.shape[0]))\n","multiples = tf.constant([23, 1])\n","reference_expected_seq = tf.tile(expected_fre, multiples)\n","\n","reference_expected_epi = mean_epi\n","\n","reference_expected = tf.concat([reference_expected_seq, reference_expected_epi], axis=1)\n","\n","reference_expected = np.ravel(reference_expected)\n","reference_expected = np.reshape(reference_expected, (1, reference_expected.shape[0]))\n","print(\"reference expected input shape: \" + str(reference_expected.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8H_6c3S0pZxv"},"outputs":[],"source":["max_index = 19\n","min_index = 16\n","max_input = concat_input[max_index]\n","min_input = concat_input[min_index]\n","max_input = np.reshape(max_input, (1, 23, 8))\n","min_input = np.reshape(min_input, (1, 23, 8))\n","\n","print(\"max data shape: \" + str(max_input.shape))\n","print(\"min data shape: \" + str(min_input.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Omzy5I9qI0ep"},"outputs":[],"source":["def draw_shap_map(saliency_map, title_name):\n","    # Normalize the saliency map\n","    saliency_map /= (tf.reduce_max(tf.abs(saliency_map)) + 1e-8)\n","\n","    # Transpose the map to match the format in the paper\n","    saliency_map = np.transpose(saliency_map)\n","\n","    # Create a heatmap by applying a colormap (e.g., 'viridis')\n","    heatmap = plt.get_cmap('viridis')(saliency_map)\n","\n","    # Display the original image, saliency map, and overlaid image\n","    plt.figure(figsize=(12, 6))\n","    plt.imshow(saliency_map, cmap='viridis')\n","    plt.colorbar()\n","\n","    plt.title(title_name)\n","    y_ticks = np.arange(0, 8, 1)  # Custom tick locations\n","    y_tick_labels = ['A', 'C', 'G', 'T', 'CTCF', 'Dnase', 'H3k4me3', 'RRBS']  # Custom tick labels\n","\n","    x_ticks = np.arange(0, 23, 1)  # Custom tick locations\n","    x_tick_labels = np.arange(1, 24, 1)  # Custom tick labels\n","\n","    plt.xticks(x_ticks, x_tick_labels)\n","    plt.yticks(y_ticks, y_tick_labels)\n","\n","    plt.xlabel('Genomic Position')\n","    plt.ylabel('Nucleotide')\n","\n","    plt.show()"]},{"cell_type":"markdown","source":["### CNNSVR"],"metadata":{"id":"9pxUpJYTVBRU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3c-cwiOncnM"},"outputs":[],"source":["max_embed = model.predict(max_input)[:, selected_cnn_fea_cols]\n","min_embed = model.predict(min_input)[:, selected_cnn_fea_cols]\n","\n","max_pred = clf.predict(max_embed)\n","min_pred = clf.predict(min_embed)\n","\n","print(\"max data model prediction: \" + str(max_pred))\n","print(\"min data model prediction: \" + str(min_pred))\n","\n","\n","max_data = np.ravel(max_input)\n","max_data = np.reshape(max_data, (1, max_data.shape[0]))\n","print(\"max data shape: \" + str(max_data.shape))\n","\n","min_data = np.ravel(min_input)\n","min_data = np.reshape(min_data, (1, min_data.shape[0]))\n","print(\"min data shape: \" + str(min_data.shape))\n","\n","def f(X):\n","  num_sample = X.shape[0]\n","  input = np.reshape(X, (num_sample, 23, 8))\n","  embed = model.predict(input)[:, selected_cnn_fea_cols]\n","  return clf.predict(embed)"]},{"cell_type":"markdown","metadata":{"id":"gPM8vQ3DS3a8"},"source":["Explainer using reference zeroes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nh6f8q5aSsk9"},"outputs":[],"source":["# Explainer using reference_zeros\n","explainer = shap.KernelExplainer(f, reference_zeroes)\n","print(\"expected importance for the reference value: \" + str(explainer.expected_value))\n","\n","shap_values_max = explainer.shap_values(max_data)\n","shap_values_min = explainer.shap_values(min_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPjQ5DEBIShd"},"outputs":[],"source":["shap.initjs()\n","\n","shap_values_max = np.reshape(shap_values_max, (23,8))\n","seq_max, epi_max = np.split(shap_values_max, 2, axis = 1)\n","\n","shap_values_min = np.reshape(shap_values_min, (23,8))\n","seq_min, epi_min = np.split(shap_values_min, 2, axis = 1)\n","\n","# project the importance at each position onto the base that's actually present\n","seq_input_max, epi_input_max = np.split(max_input[0], 2, axis = 1)\n","seq_input_min, epi_input_min = np.split(min_input[0], 2, axis = 1)\n","\n","print(seq_input_max)\n","print(seq_input_min)\n","\n","\n","processed_max = (\n","    np.sum(seq_max, axis=-1)[:, None] * seq_input_max\n",")\n","\n","processed_min = (\n","    np.sum(seq_min, axis=-1)[:, None] * seq_input_min\n",")\n","print(processed_max)\n","print(processed_min)\n","\n","viz_sequence.plot_weights(processed_max, subticks_frequency=1)\n","viz_sequence.plot_weights(processed_min, subticks_frequency=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OEczkNkI6lQ"},"outputs":[],"source":["draw_shap_map(shap_values_max, 'SHAP Value for max')\n","\n","draw_shap_map(shap_values_min, 'SHAP Value for min')"]},{"cell_type":"markdown","metadata":{"id":"t71Gj8oaT1uX"},"source":["Explainer using reference expected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gyFN79YTDFA"},"outputs":[],"source":["# Explainer using reference_expected\n","explainer = shap.KernelExplainer(f, reference_expected)\n","print(\"expected importance for the reference value: \" + str(explainer.expected_value))\n","\n","shap_values_max = explainer.shap_values(max_data)\n","shap_values_min = explainer.shap_values(min_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYSFxWGeT4xL"},"outputs":[],"source":["shap.initjs()\n","\n","shap_values_max = np.reshape(shap_values_max, (23,8))\n","seq_max, epi_max = np.split(shap_values_max, 2, axis = 1)\n","\n","shap_values_min = np.reshape(shap_values_min, (23,8))\n","seq_min, epi_min = np.split(shap_values_min, 2, axis = 1)\n","\n","# project the importance at each position onto the base that's actually present\n","seq_input_max, epi_input_max = np.split(max_input[0], 2, axis = 1)\n","seq_input_min, epi_input_min = np.split(min_input[0], 2, axis = 1)\n","\n","print(seq_input_max)\n","print(seq_input_min)\n","\n","\n","processed_max = (\n","    np.sum(seq_max, axis=-1)[:, None] * seq_input_max\n",")\n","\n","processed_min = (\n","    np.sum(seq_min, axis=-1)[:, None] * seq_input_min\n",")\n","print(processed_max)\n","print(processed_min)\n","\n","viz_sequence.plot_weights(processed_max, subticks_frequency=1)\n","viz_sequence.plot_weights(processed_min, subticks_frequency=1)"]},{"cell_type":"code","source":["draw_shap_map(shap_values_max, 'SHAP Value for max')\n","\n","draw_shap_map(shap_values_min, 'SHAP Value for min')"],"metadata":{"id":"gyCQKuSKWgJ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CRNNCrispr"],"metadata":{"id":"yxGgEb2GunD9"}},{"cell_type":"code","source":["max_pred = CRNNCrispr_model.predict(max_input)\n","min_pred = CRNNCrispr_model.predict(min_input)\n","\n","print(\"max data model prediction: \" + str(max_pred))\n","print(\"min data model prediction: \" + str(min_pred))\n","\n","\n","max_data = np.ravel(max_input)\n","max_data = np.reshape(max_data, (1, max_data.shape[0]))\n","print(\"max data shape: \" + str(max_data.shape))\n","\n","min_data = np.ravel(min_input)\n","min_data = np.reshape(min_data, (1, min_data.shape[0]))\n","print(\"min data shape: \" + str(min_data.shape))\n","\n","def f(X):\n","  num_sample = X.shape[0]\n","  input = np.reshape(X, (num_sample, 23, 8))\n","  return CRNNCrispr_model.predict(input)"],"metadata":{"id":"hqF5_foB0mV3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Explainer using reference zeroes"],"metadata":{"id":"fhh-MwpxXVgd"}},{"cell_type":"code","source":["explainer = shap.KernelExplainer(f, reference_zeroes)\n","print(\"expected importance for the reference value: \" + str(explainer.expected_value))\n","\n","shap_values_max = explainer.shap_values(max_data)\n","shap_values_min = explainer.shap_values(min_data)"],"metadata":{"id":"xMeBc2nrW4r7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.initjs()\n","\n","shap_values_max = np.reshape(shap_values_max, (23,8))\n","seq_max, epi_max = np.split(shap_values_max, 2, axis = 1)\n","\n","shap_values_min = np.reshape(shap_values_min, (23,8))\n","seq_min, epi_min = np.split(shap_values_min, 2, axis = 1)\n","\n","# project the importance at each position onto the base that's actually present\n","\n","# print(seq_max)\n","# print(seq[0])\n","\n","\n","seq_input_max, epi_input_max = np.split(max_input[0], 2, axis = 1)\n","seq_input_min, epi_input_min = np.split(min_input[0], 2, axis = 1)\n","\n","print(seq_input_max)\n","print(seq_input_min)\n","\n","\n","processed_max = (\n","    np.sum(seq_max, axis=-1)[:, None] * seq_input_max\n",")\n","\n","processed_min = (\n","    np.sum(seq_min, axis=-1)[:, None] * seq_input_min\n",")\n","print(processed_max)\n","print(processed_min)\n","\n","viz_sequence.plot_weights(processed_max, subticks_frequency=1)\n","viz_sequence.plot_weights(processed_min, subticks_frequency=1)"],"metadata":{"id":"I1NWpc0cNtJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_shap_map(shap_values_max, 'SHAP Value for max')\n","\n","draw_shap_map(shap_values_min, 'SHAP Value for min')"],"metadata":{"id":"gVsfzNTPZ-sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Explainer using reference expected"],"metadata":{"id":"2xgry4QhXXAC"}},{"cell_type":"code","source":["expected_explainer = shap.KernelExplainer(f, reference_expected)\n","print(\"expected importance for the reference value: \" + str(expected_explainer.expected_value))\n","\n","shap_values_max = explainer.shap_values(max_data)\n","shap_values_min = explainer.shap_values(min_data)"],"metadata":{"id":"LEiE9CMVW089"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.initjs()\n","\n","shap_values_max = np.reshape(shap_values_max, (23,8))\n","seq_max, epi_max = np.split(shap_values_max, 2, axis = 1)\n","\n","shap_values_min = np.reshape(shap_values_min, (23,8))\n","seq_min, epi_min = np.split(shap_values_min, 2, axis = 1)\n","\n","# project the importance at each position onto the base that's actually present\n","\n","# print(seq_max)\n","# print(seq[0])\n","\n","\n","seq_input_max, epi_input_max = np.split(max_input[0], 2, axis = 1)\n","seq_input_min, epi_input_min = np.split(min_input[0], 2, axis = 1)\n","\n","print(seq_input_max)\n","print(seq_input_min)\n","\n","\n","processed_max = (\n","    np.sum(seq_max, axis=-1)[:, None] * seq_input_max\n",")\n","\n","processed_min = (\n","    np.sum(seq_min, axis=-1)[:, None] * seq_input_min\n",")\n","print(processed_max)\n","print(processed_min)\n","\n","viz_sequence.plot_weights(processed_max, subticks_frequency=1)\n","viz_sequence.plot_weights(processed_min, subticks_frequency=1)"],"metadata":{"id":"oEvrO69UW1VG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_shap_map(shap_values_max, 'SHAP Value for max')\n","\n","draw_shap_map(shap_values_min, 'SHAP Value for min')"],"metadata":{"id":"u3QGN9poW1gD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SHAP Examples with CRNNCrispr\n"],"metadata":{"id":"5LS30IMFGyDz"}},{"cell_type":"code","source":["%matplotlib inline\n","from __future__ import print_function, division"],"metadata":{"id":"QtQ-L6IeG0Uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! [[ ! -f sequences.simdata.gz ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/db919b12f750e5844402153233249bb3d24e9e9a/deeplift/genomics/sequences.simdata.gz\n","! [[ ! -f keras2_conv1d_record_5_model_PQzyq_modelJson.json ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/b6e1d69/deeplift/genomics/keras2_conv1d_record_5_model_PQzyq_modelJson.json\n","! [[ ! -f keras2_conv1d_record_5_model_PQzyq_modelWeights.h5 ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/b6e1d69/deeplift/genomics/keras2_conv1d_record_5_model_PQzyq_modelWeights.h5\n","! [[ ! -f test.txt.gz ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/9aadb769735c60eb90f7d3d896632ac749a1bdd2/deeplift/genomics/test.txt.gz"],"metadata":{"id":"MyLPa1SDG8Bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install simdna\n","! pip install shap"],"metadata":{"id":"PhtgIN9NHABE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gzip\n","\n","import simdna.synthetic as synthetic\n","\n","data_filename = \"sequences.simdata.gz\"\n","\n","# read in the data in the testing set\n","test_ids_fh = gzip.open(\"test.txt.gz\", \"rb\")\n","ids_to_load = [x.decode(\"utf-8\").rstrip(\"\\n\") for x in test_ids_fh]\n","data = synthetic.read_simdata_file(data_filename, ids_to_load=ids_to_load)"],"metadata":{"id":"M5acB4uWHDIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","# this is set up for 1d convolutions where examples\n","# have dimensions (len, num_channels)\n","# the channel axis is the axis for one-hot encoding.\n","def one_hot_encode_along_channel_axis(sequence):\n","    to_return = np.zeros((len(sequence), 4), dtype=np.int8)\n","    seq_to_one_hot_fill_in_array(\n","        zeros_array=to_return, sequence=sequence, one_hot_axis=1\n","    )\n","    return to_return\n","\n","\n","def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n","    assert one_hot_axis == 0 or one_hot_axis == 1\n","    if one_hot_axis == 0:\n","        assert zeros_array.shape[1] == len(sequence)\n","    elif one_hot_axis == 1:\n","        assert zeros_array.shape[0] == len(sequence)\n","    # will mutate zeros_array\n","    for i, char in enumerate(sequence):\n","        if char == \"A\" or char == \"a\":\n","            char_idx = 0\n","        elif char == \"C\" or char == \"c\":\n","            char_idx = 1\n","        elif char == \"G\" or char == \"g\":\n","            char_idx = 2\n","        elif char == \"T\" or char == \"t\":\n","            char_idx = 3\n","        elif char == \"N\" or char == \"n\":\n","            continue  # leave that pos as all 0's\n","        else:\n","            raise RuntimeError(\"Unsupported character: \" + str(char))\n","        if one_hot_axis == 0:\n","            zeros_array[char_idx, i] = 1\n","        elif one_hot_axis == 1:\n","            zeros_array[i, char_idx] = 1\n","\n","\n","onehot_data = np.array(\n","    [one_hot_encode_along_channel_axis(seq) for seq in data.sequences]\n",")"],"metadata":{"id":"snAe0lYsKt_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import model_from_json\n","\n","# load the keras model\n","keras_model_weights = \"keras2_conv1d_record_5_model_PQzyq_modelWeights.h5\"\n","keras_model_json = \"keras2_conv1d_record_5_model_PQzyq_modelJson.json\"\n","\n","keras_model = model_from_json(open(keras_model_json).read())\n","keras_model.load_weights(keras_model_weights)"],"metadata":{"id":"hOUkNlp3Kwk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install --upgrade deeplift==0.6.10.0"],"metadata":{"id":"sjdmWjQHHKgG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import deeplift\n","import shap\n","print(\"deeplift version is:\", deeplift.__version__)\n","print(\"shap version is:\", shap.__version__)"],"metadata":{"id":"MoWu69uDJ0pL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from deeplift.dinuc_shuffle import (\n","    prepare_edges,\n","    shuffle_edges,\n","    traverse_edges,\n",")\n","\n","\n","def onehot_dinuc_shuffle(s):\n","    s = np.squeeze(s)\n","    argmax_vals = \"\".join([str(x) for x in np.argmax(s, axis=-1)])\n","    shuffled_argmax_vals = [\n","        int(x)\n","        for x in traverse_edges(argmax_vals, shuffle_edges(prepare_edges(argmax_vals)))\n","    ]\n","    to_return = np.zeros_like(s)\n","    to_return[list(range(len(s))), shuffled_argmax_vals] = 1\n","    return to_return\n","\n","\n","def shuffle_several_times(s):\n","    return np.array([onehot_dinuc_shuffle(s) for i in range(100)])"],"metadata":{"id":"ZhfvOPLPKyxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from deeplift.visualization import viz_sequence\n","\n","import shap\n","import shap.explainers._deep.deep_tf\n","\n","np.random.seed(1)\n","seqs_to_explain = onehot_data[[0, 3, 9]]  # these three are positive for task 0\n","\n","# print(seqs_to_explain.shape)\n","# reference_val = np.zeros(seqs_to_explain[0].shape)\n","# reference_val = np.reshape(reference_val, (1, 200, 4))\n","\n","\n","dinuc_shuff_explainer = shap.DeepExplainer(\n","    (keras_model.input, keras_model.output[:, 0]), shuffle_several_times\n",")\n","print(dinuc_shuff_explainer.expected_value)\n","\n","\n","raw_shap_explanations = dinuc_shuff_explainer.shap_values(seqs_to_explain)\n","\n","# project the importance at each position onto the base that's actually present\n","dinuc_shuff_explanations = (\n","    np.sum(raw_shap_explanations, axis=-1)[:, :, None] * seqs_to_explain\n",")\n","for dinuc_shuff_explanation in dinuc_shuff_explanations:\n","    viz_sequence.plot_weights(dinuc_shuff_explanation, subticks_frequency=20)"],"metadata":{"id":"esru33QdK4od"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}